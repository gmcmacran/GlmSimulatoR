---
title: "Count Data And Overdispersion"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Count Data And Overdispersion}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  results = "hide"
)
```

## Overview

For count response variables, the glm framework has two options. The Poisson family and the negative binomial family. In this vignette, we will consider both and learn when to use one or the other.


## Getting familiar with the Poisson family

First lets get an idea of how the Poisson family looks. If lambda is near 1, the Poisson family is right skewed. As lambda increases, the Poisson family becomes more symmetrical. 

```{r PoissonHistogram, echo=TRUE}
library(stats)
library(MASS)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(GlmSimulatoR)

set.seed(1)

# lambda 1
poisson <- rpois(n = 10000, lambda = 1)
poisson_df <- as_tibble(poisson)

ggplot(poisson_df, aes(value)) +
  geom_histogram(bins = 100)

# lambda 5
poisson <- rpois(n = 10000, lambda = 5)
poisson_df <- as_tibble(poisson)

ggplot(poisson_df, aes(value)) +
  geom_histogram(bins = 100)

# lambda 10
poisson <- rpois(n = 10000, lambda = 10)
poisson_df <- as_tibble(poisson)

ggplot(poisson_df, aes(value)) +
  geom_histogram(bins = 100)
```

```{r, echo=FALSE}
rm(poisson, poisson_df)
```


## GLM Poisson
Lets create data and train a model. 

```{r PoissonGlm, echo=TRUE, results='markup'}
set.seed(1)
simdata <- simulate_poisson(N = 10000, weights = c(.5, 1), link = "log")

# Response looks similar to above histograms
ggplot(simdata, aes(Y)) +
  geom_histogram(bins = 100)

glm_poisson <- glm(Y ~ X1 + X2, data = simdata, family = poisson(link = "log"))
summary(glm_poisson)
```

The estimated weights are close the the weights argument in simulate_poisson. The model estimates are accurate.

```{r, echo=FALSE}
rm(simdata, glm_poisson)
```

## Poisson vs Negative Binomial
For modeling, the main difference between Poisson and the negative binomial is the extra parameter. For the Poisson distribution, the mean-variance relationship is $\sigma^2 =\mu$. For the negative binomial  distribution, the mean-variance relationship is $\sigma^2 = \mu + \mu^2/\theta$.  Through $\theta$, a more flexible relationships is possible.

## Getting familiar with the negative binomial family
When $\theta$ is large, $\mu + \mu^2/\theta$ is roughly equal to $\mu$ . Therefore the negative binomial will be similar to Poisson distribution.

```{r PoissonNegativeBinomial1, echo=TRUE}
set.seed(1)

poisson <- rpois(n = 10000, lambda = 1)
poisson_df <- as_tibble(poisson)

ggplot(poisson_df, aes(value)) +
  geom_histogram(bins = 100)

neg_bin_rv <- rnegbin(n = 10000, mu = 1, theta = 1000)
neg_bin_df <- as_tibble(neg_bin_rv)

ggplot(neg_bin_df, aes(value)) +
  geom_histogram(bins = 100)
```

```{r, echo=FALSE}
rm(poisson, poisson_df, neg_bin_rv, neg_bin_df)
```


If $\theta$ is small, $\mu + \mu^2/\theta$ does not approximately equal $\mu$. The negative binomial will look different than the Poisson distribution. Note the difference in scale on the x axis and y axis.


```{r PoissonNegativeBinomial2, echo=TRUE}
set.seed(1)

poisson <- rpois(n = 10000, lambda = 1)
poisson_df <- as_tibble(poisson)

ggplot(poisson_df, aes(value)) +
  geom_histogram(bins = 100)

neg_bin_rv <- rnegbin(n = 10000, mu = 1, theta = 1)
neg_bin_df <- as_tibble(neg_bin_rv)

ggplot(neg_bin_df, aes(value)) +
  geom_histogram(bins = 100)
```

```{r, echo=FALSE}
rm(poisson, poisson_df, neg_bin_rv, neg_bin_df)
```

## GLM Negative Binomial
Lets create data where the flexibility of the negative binomial is needed and compare the Poisson estimates to the negative binomial estimates. 

```{r NegativeBinomialGlm, echo=TRUE, results='markup'}
set.seed(1)
simdata <- simulate_negative_binomial(
  N = 10000, weights = c(.5, 1),
  ancillary = 5, link = "log"
) # ancillary is theta.

# Response looks like a negative binomial distribution.
ggplot(simdata, aes(Y)) +
  geom_histogram(bins = 200)

glm_poisson <- glm(Y ~ X1 + X2, data = simdata, family = poisson(link = "log"))
glm_nb <- glm.nb(Y ~ X1 + X2, data = simdata, link = "log")

summary(glm_poisson)
summary(glm_nb)
```

```{r, echo=FALSE}
rm(simdata, glm_poisson, glm_nb)
```
The estimated slopes are very similar. However, the standard errors are not. The fact $\mu$ does not equal $\sigma^2$ has caused a major under estimation of standard errors for the Poisson GLM.

For Poisson models, it is important to look at residual deviance divided by the degrees of freedom. When this quotient is larger than 1, the negative binomial should be considered. In the above the quotient was 6.33 (63327 / 9997) for the Poisson glm.
