---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```
# GlmSimulatoR
 
<!-- badges: start -->
[![CRAN status](https://www.r-pkg.org/badges/version/GlmSimulatoR)](https://cran.r-project.org/package=GlmSimulatoR)
[![R build status](https://github.com/gmcmacran/GlmSimulatoR/workflows/R-CMD-check/badge.svg)](https://github.com/gmcmacran/GlmSimulatoR/actions)
[![Codecov test coverage](https://codecov.io/gh/gmcmacran/GlmSimulatoR/branch/master/graph/badge.svg)](https://codecov.io/gh/gmcmacran/GlmSimulatoR?branch=master)
<!-- badges: end -->

Often the first problem in understanding statistical models is finding good data. This package alleviates this by creating data perfect for generalized linear models. With data in hand, you can focus on questions about models instead of questions about data. Are the estimated weights close to the true values? Does step wise search pick the correct variables? At what n does the sampling distribution of weights normalize?

## Package Overview
All functions return a tibble. The only thing that changes is the distribution of Y. In simulate_gaussian, Y follows a Gaussian distribution. In simulate_gamma, Y follows a gamma distribution. Common and novel distributions are implemented. For each distribution, all links are implemented.

## Is A Sample Size Of 200 Enough To Get Close Estimates Of The True Weights?

```{r setup}
set.seed(1)
simdata <- simulate_gaussian(N = 200, weights = c(1, 2, 3))

model <- lm(Y ~ X1 + X2 + X3, data = simdata)
summary(model)$coefficients

```

In the above, we see the estimates are close to the weights argument. The mathematics behind the generalized linear model worked well.

See vignettes for more examples.
